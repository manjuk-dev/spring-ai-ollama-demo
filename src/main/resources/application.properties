# ==========================================
# General Application Settings
# ==========================================
spring.application.name=ollama-demo

# ==========================================
# Ollama Connection & Model Selection
# ==========================================
spring.ai.ollama.base-url=http://localhost:11434
spring.ai.ollama.chat.options.model=llama3.2:1b
spring.ai.ollama.embedding.options.model=nomic-embed-text

# ==========================================
# Performance & Stability (Fixes Hangs/Loops)
# ==========================================
# Prevents the app from hanging on startup to download models
spring.ai.ollama.init.pull-model-strategy=never

# Keeps the model in RAM for 20 minutes to avoid reloading delays
spring.ai.ollama.chat.options.keep-alive=20m

# Prevents the browser from "rotating" forever if Ollama is slow
spring.ai.ollama.chat.options.timeout=30s

# ==========================================
# AI Behavior & Output Quality
# ==========================================
# Lower temperature (0.4-0.6) makes small models more focused/less crazy
spring.ai.ollama.chat.options.temperature=0.5

# High repeat penalty stops the model from looping the same sentence
spring.ai.ollama.chat.options.repeat-penalty=1.5

# Limits response length to prevent runaway generation
spring.ai.ollama.chat.options.num-predict=200

# ==========================================
# Disable Unnecessary Modules
# ==========================================
# Disable Embeddings (Stops the mxbai-embed-large auto-pull)
spring.ai.ollama.embedding.enabled=false
spring.ai.model.embedding.enabled=false

# Disable unused OpenAI components to avoid startup warnings
spring.ai.openai.chat.enabled=false
spring.ai.openai.audio.speech.enabled=false