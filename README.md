# ğŸš€ Spring AI + Ollama: Local LLM Demo

This project demonstrates a "Privacy-First" AI implementation using **Spring Boot 3** and **Ollama**. It allows you to run a Large Language Model (LLM) entirely on your local machineâ€”no API keys or internet connection required for inference.

## ğŸ› ï¸ Tech Stack
- **Framework:** Spring Boot 3.x
- **AI Integration:** Spring AI
- **LLM Runner:** Ollama
- **Model:** Llama 3.2 (1B Parameters)

## ğŸ“‹ Prerequisites
1. Install [Ollama](https://ollama.com/).
2. Download the lightweight Llama model:
   ```bash
   ollama pull llama3.2:1b